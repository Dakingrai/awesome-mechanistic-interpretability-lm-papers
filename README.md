# awesome-mechanistic-interpretability-LM-papers

This is a collection of awesome papers about Mechanistic Interpretability (MI) for Transformer-based Language Models (LMs), organized following our survey paper: [A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models](https://arxiv.org/pdf/2407.02646). 

Papers are organized following our **taxonomy (Figure 1)**. 
We have also curated a **Beginner's Roadmap (Figure 2)** with actionable items for interested people using MI for their purposes.

<div align="center">
  <img src="images/taxonomy.png" width="70%"/>
  <p>Figure 1: Taxonomy</p>
</div>

<div align="center">
  <img src="images/roadmap.png" width="50%"/>
  <p>Figure 2: Beginner's Roadmap</p>
</div>

**How to Contribute:** We welcome contributions from everyone! If you find any relevant papers that are not included in the list, please categorize them following our taxonomy and submit a request for update.


**Questions/Comments/Suggestions:** If you have any questions/comments/suggestions to share with us, you are welcome to report an issue here or reach out to us through drai2@gmu.edu and ziyuyao@gmu.edu.

**How to Cite:** If you find our survey useful for your research, please cite our paper:
```
@article{rai2024practical,
  title={A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models},
  author={Rai, Daking and Zhou, Yilun and Feng, Shi and Saparov, Abulhair and Yao, Ziyu},
  journal={arXiv preprint arXiv:2407.02646},
  year={2024}
}
```

## Updates
- June 2024: GitHub repository launched! Still under construction.

## Table of Contents
- [Techniques](#mi-techniques)
- [Evaluation](#evaluation)
- [Findings and Applications](#findings)
  - [Findings on features](#features)
    - [Polysemanticity](#polysemanticity)
    - [Superposition](#superposition)
  - [Findings on circuits](#circuits)
    - [Interpreting LM Behaviors](#lm-behavior-interpret)
    - [Interpreting Transformer Components](#transformer-component-interpret)
  - [Findings on Universality](#universality)
  - [Findings on Model Capabilities](#model-capability-interpret)
    - [In-context Learning](#in-context-learning)
    - [Reasoning](#reasoning)
    - [Others](#others-model-capabilities)
  - [Findings on Learning Dynamics](#learning-dynamics)
    - [Phase Changes during LM Training](#phase-changes)
    - [Learning Dynamics during LM Fine-Tuning](#finetuning)
  - [Applications of MI](#mi-application)
    - [Model Enhancement](#model-enhancement)
      - [Knowledge Editing][#knowledge-editing]
      - [LM Generation Steering](#lm-generation-steering)
    - [AI Safety](#ai-safety)
    - [Others](#others-application)

## Paper Collection

### Techniques

### Evaluation

### Findings and Applications

### Opinions and Discussions

### Other Resources

